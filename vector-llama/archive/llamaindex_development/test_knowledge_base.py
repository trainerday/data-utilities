#!/usr/bin/env python3
"""
Simple test of the loaded knowledge base
"""

import os
from pathlib import Path
from dotenv import load_dotenv

from llama_index.core import StorageContext, load_index_from_storage, Settings, PromptTemplate
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from llama_index.core.postprocessor import SimilarityPostprocessor

load_dotenv()

def test_knowledge_base():
    """Test the loaded knowledge base"""
    
    # Configure LlamaIndex
    Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-large", dimensions=1536)
    Settings.llm = OpenAI(model="gpt-4-turbo-preview", temperature=0.1)
    
    # Load index
    storage_dir = Path("./llamaindex_storage")
    
    if not storage_dir.exists():
        print("‚ùå No index found")
        return
    
    try:
        print("Loading TrainerDay knowledge base...")
        storage_context = StorageContext.from_defaults(persist_dir=str(storage_dir))
        index = load_index_from_storage(storage_context)
        print("‚úÖ Knowledge base loaded successfully")
        
        # Test search with different thresholds
        test_queries = [
            "What is Coach Jack?",
            "How does FTP testing work?", 
            "Indoor cycling setup guide",
            "Ride Feel feature explained"
        ]
        
        print(f"\\nüìä Testing with {len(test_queries)} queries...")
        
        for threshold in [0.4, 0.5, 0.6]:
            print(f"\\n{'='*60}")
            print(f"TESTING WITH SIMILARITY THRESHOLD: {threshold}")
            print(f"{'='*60}")
            
            # Create query engine with threshold
            engine = index.as_query_engine(
                response_mode="compact",
                similarity_top_k=3,
                node_postprocessors=[
                    SimilarityPostprocessor(similarity_cutoff=threshold)
                ]
            )
            
            for query in test_queries:
                print(f"\\nQuery: {query}")
                print("-" * 40)
                
                try:
                    response = engine.query(query)
                    
                    if hasattr(response, 'source_nodes') and response.source_nodes:
                        print(f"‚úÖ Found {len(response.source_nodes)} sources")
                        for i, node in enumerate(response.source_nodes):
                            title = node.metadata.get('title', 'Unknown')
                            score = getattr(node, 'score', 0.0)
                            print(f"  {i+1}. {title} (score: {score:.3f})")
                        
                        print(f"Response: {str(response)[:150]}...")
                    else:
                        print("‚ùå No sources found above threshold")
                        
                except Exception as e:
                    print(f"‚ùå Error: {e}")
        
        # Show available content overview
        print(f"\\n{'='*60}")
        print("CONTENT OVERVIEW")
        print(f"{'='*60}")
        
        # Get some sample content
        retriever = index.as_retriever(similarity_top_k=10)
        sample_nodes = retriever.retrieve("TrainerDay features")
        
        print(f"Sample of available content:")
        for i, node in enumerate(sample_nodes[:5]):
            title = node.metadata.get('title', 'Unknown')
            category = node.metadata.get('category', 'Unknown')
            print(f"  {i+1}. {title} ({category})")
        
        print(f"\\nüéâ Knowledge base is working!")
        print(f"üìö 69 blog articles loaded and searchable")
        print(f"üí∞ Cost so far: ~$0.01 for embeddings")
        print(f"üîç Ready for blog post generation and fact extraction")
        
    except Exception as e:
        print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    test_knowledge_base()